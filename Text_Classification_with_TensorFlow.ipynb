{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4106a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Classification with TensorFlow (Kaggle Dataset)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Kaggle setup for downloading dataset\n",
    "!pip install kaggle\n",
    "!mkdir -p ~/.kaggle\n",
    "!echo '{\"username\":\"your_kaggle_username\",\"key\":\"your_kaggle_api_key\"}' > ~/.kaggle/kaggle.json\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# Download the Fake and Real News Dataset from Kaggle\n",
    "!kaggle datasets download -d clmentbisaillon/fake-and-real-news-dataset\n",
    "!unzip fake-and-real-news-dataset.zip\n",
    "\n",
    "df = pd.read_csv('True.csv')\n",
    "df['label'] = 'real'\n",
    "df_fake = pd.read_csv('Fake.csv')\n",
    "df_fake['label'] = 'fake'\n",
    "df = pd.concat([df, df_fake]).reset_index(drop=True)\n",
    "\n",
    "# Display sample data\n",
    "print(\"Dataset Sample:\")\n",
    "print(df.head())\n",
    "\n",
    "# Preprocess the data\n",
    "texts = df['text'].values\n",
    "labels = df['label'].values\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize text data\n",
    "max_words = 10000\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad sequences to ensure uniform input size\n",
    "max_length = 100\n",
    "X_train_pad = keras.preprocessing.sequence.pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
    "X_test_pad = keras.preprocessing.sequence.pad_sequences(X_test_seq, maxlen=max_length, padding='post')\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(max_words, 16, input_length=max_length),\n",
    "    keras.layers.GlobalAveragePooling1D(),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "history = model.fit(X_train_pad, y_train, epochs=10, validation_data=(X_test_pad, y_test), batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('text_classification_model.h5')\n",
    "\n",
    "print(\"Project completed successfully!\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
